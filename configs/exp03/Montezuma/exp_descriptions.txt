virtual memory'miz fazla --> htop (VIRT)

exps:
64 processli devam
--
1)düz ppo montezuma
2) intrinsic loss'u 1000 yerine 100 e bölmeli original+modified+RND
3) kızın 32 rnd arkada devam
4) 16 processlie montezuma dursun
5,6) intrinsic loss'u 1000 yerine 10 e bölmeli original+modified+RND
* boş kalana da düz ppo montezuma gerisi

2000 step'te haber 

===== Summary:
Montezuma 64 process (detaylı loglamayı da kapat bence daha hızlı trainleyebilir !!!):
	1) Just PPO  
	2,3) intrinsic loss'u 1000 yerine 100'e bolmeli -> (original_rnd + modified_rnd) = [IntCoef = 0.1] (Note original IntCoef=1)
	4,5) intrinsic loss'u 1000 yerine 10'a bolmeli -> (original_rnd + modified_rnd) = [IntCoef = 0.01] (Note original IntCoef=1)
	-
	6) kızın 32 process'li rnd'si arkada devam etsin.
	7) bizim 64 process montezuma devam etsin. [tb_logs/montezuma_originalRND00_parallel_exp2]
	8) bizim 16 process montezuma devam etsin. [tb_logs/montezuma_originalRND00_parallel_exp4]
	-
	7,8) boş kalana da düz ppo montezuma gerisi farklı process sayılarıyla dene (max alabildiğin process spawn sayıyısını arıyoruz)
		or
	     scalene ve torchprofiler runla
	        or
	     rdzv-endpoint'li bir çalışacak mı diye 64 process'li 2 node da deneybillirsin belki ?
	
	= 2000 step'de Barış hocaya sonuçları bildir (~Çarşamba sabahı)
====

default Coefficients:
** critic_loss = critic_ext_loss + critic_int_loss **
*** loss = actor_loss + 0.5 * critic_loss - self.ent_coef * entropy + rnd_loss + self.representation_loss_coef * representation_loss ***

	*) self.ent_coef --> 0.01 (config'de bile değil direk default bu bununla oynama bence) 
	*) self.representation_loss_coef --> 1.0 (Barlow ve BYOL'da da aynı)
	
*** total_adv = int_adv * int_coef + ext_adv * ext_coef ***
	*) IntCoef = 1
	*) ExtCoef = 2


self.ent_coef --> 0.01 (config'de bile değil direk default bu bununla oynama bence)

---------
=============================================================================================
*********************************************************************************************
=============================================================================================
---------
Barış hoca 2. görüşme:

modified RND 128'den 1024 feature embedding e çıkar 
original RND intrinsicleri 10, 100, 1000 katına çıkar
düz ppo devam
16 ve 64 processli montezuma original rnd'ler devam

rnd ve latent rnd (NOTE: latent dediği modified RND)
1,2) latent rnd 1024 1 ve 1000 kat

modified RND 256 feature size'ı 10

============= Summary:
	1,2,3) original RND intrinsic coefficient'ları 10, 100, ve 1000 katına çıkar = [IntCoef = 10], [IntCoef = 100], [IntCoef = 1000] {Montezuma_originalRND00_intCoef10_exp1_7day_batchjob, Montezuma_originalRND00_intCoef100_exp2_7day_batchjob, Montezuma_originalRND00_intCoef1000_exp3_7day_batchjob}
	4,5) modified RND 128'den 1024 feature embedding'e çıkar: intrinsic coefficient'ları 1 ve 1000 ile dene = [IntCoef = 1], [IntCoef = 1000] {can_montezuma_modifiedRND00_intCoef1_1024embed_exp4_submit, can_montezuma_modifiedRND00_intCoef1000_1024embed_exp5_submit}
	-- (devam ettirilenler)
	6) JustPPO training'i devam etsin {Montezuma_JustPPO00_exp1_7day_batchjob}
	7,8) 64 ve 32 process'li original RND training'leri devam etsin {Montezuma_originalRND00_parallel_exp2_7day_batchjob, Montezuma_originalRND00_parallel_exp4_7day_batchjob}
	
---------
=============================================================================================
*********************************************************************************************
=============================================================================================
---------
Barış hoca 3. görüşme:
cpu ile clusterda bir dene takılıcak mı (--mem'i de arttır baya bir)
latent size'ları varied modified_rnd + modified_rdn_BYOL

	1) 1024 embedding size, JUST_PPO {montezuma_JustPPO00_1024embed_exp1}
	2) 1024 embedding size, PPO with BYOL {montezuma_PPOwithBYOL00_1024embed_exp2}
	3) 1024 embedding size, modiifed_RND with BYOL {montezuma_modifiedRNDwithBYOL00_intCoef1000_1024embed_exp3}
	4) 1024 embedding size, original_RND with BYOL {montezuma_originalRNDwithBYOL00_intCoef1_1024embed_exp4}
	-- (devam ettirilenler)
	5) JustPPO (128 embed) training'i devam etsin {Montezuma_JustPPO00_exp1_7day_batchjob}
	6, 7) 64 ve 32 process'li original RND training'leri devam etsin {Montezuma_originalRND00_parallel_exp2_7day_batchjob, Montezuma_originalRND00_parallel_exp4_7day_batchjob}
	8) modified RND 1024 feature embedding'e çıkarılan devam etsin {Montezuma_modifiedRND00_intCoef1000_1024embed_exp5_7day_batchjob}

-
Future dir:
RND ve learned network backbone paylaşsın !
